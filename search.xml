<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[mysql主从复制（读写分离）]]></title>
      <url>%2F2017%2F04%2F19%2Fmysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%EF%BC%88%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%89%2F</url>
      <content type="text"><![CDATA[mysql的主从复制或叫读写分离，适用于对mysql操作时读多写少的场景。读库（从库）只负责查询，写库（主库）负责数据的变更（新增、修改、删除），主库数据发生变化，同步到从库中去；其中还有个问题，同步的时候是有延迟的，从读库中查询到的数据，可能并不是最新的，但要保证数据的最终一致性。 读库和写库数据，最终一致性写数据（新增、修改、删除）只能在写库中完成读数据只能在读库中完成 安装两个mysql安装两个mysql，配置不同的端口。使用绿色版的，只需要做一些配置即可安装好绿色版mysql解压缩出来以后，编辑你的mysql目录/data/my.ini文件 # pipe socket=0.0 port=3380 # The TCP/IP Port the MySQL Server will listen on port=3380 # Path to the database root datadir=D:/mysql/3380/data/Data # General and Slow logging. log-output=FILE general-log=0 general_log_file=&quot;WIN-A1JA6NUDTV4.log&quot; slow-query-log=1 # 慢查询日志文件，mysql执行的SQL超过了指定的时间（执行太慢了），记录在这里，方便优化 slow_query_log_file=&quot;D:/mysql/3380/logs/mysql-slow.log&quot; long_query_time=10 # 二进制文件，记录mysql的操作 # Binary Logging. log-bin=&quot;D:/mysql/3380/logs/mysql-bin&quot; # 错误日志 方便查找问题 # Error Logging. log-error=&quot;D:/mysql/3380/logs/mysql.err.log&quot; # mysql实例的ID，不重复即可 # Server Id. server-id=380 添加 mysql系统服务，在mysql的bin目录D:\mysql\3380\bin下执行命令： D:\mysql\3380\bin&gt;.\mysqld.exe install MySQL-3380 --defaults-file=&quot;D:\mysql\3380\data\my.ini&quot; Service successfully installed. 删除系统服务sc delete MySQl-3380 启动服务： D:\mysql\3380\bin&gt;net start MySQL-3380 MySQL-3380 服务正在启动 . MySQL-3380 服务已经启动成功。 安装上以后，默认用户名是root，没有密码。设置或修改密码： D:\mysql\3380\bin&gt;mysqladmin -u root -p password Enter password: **** New password: **** Confirm new password: **** 使用客户端测试连接 安装从库 复制3380目录; D:\mysql&gt;dir 2017/01/09 10:52 &lt;DIR&gt; . 2017/01/09 10:52 &lt;DIR&gt; .. 2015/10/26 17:04 &lt;DIR&gt; 3380 2017/01/09 10:52 &lt;DIR&gt; 3381 0 个文件 0 字节 4 个目录 61,139,161,088 可用字节 删除所有的日志文件删除3381/logs目录下所有文件；删除3381\data目录下所有日志文件 修改my.ini配置文件的端口和目录。 修改server-id，不要与3380的server-id重复 从库安装完毕。此时3380、3381两个不同端口的数据都可以正常连接。 建立主从关系mysql的主从复制原理：mysql是将主库(master/写库)的变更记录下来，记录到二进制文件中；从库(slave/读库)读取该文件并执行，即可完成主从复制。 主-从存在数据延迟问题，不可避免 主从配置需要注意的地方：数据需要在同一基准下 主库和从库数据库的版本一致 主库和从库数据库数据一致[ 这里就会可以把主的备份在从上还原，也可以直接将主的数据目录拷贝到从的相应数据目录] 主库开启二进制日志,主库和从库的server_id都必须唯一 主从复制的配置：主库配置主库my.ini配置文件中： 开启主从复制，主库的配置 log-bin=&quot;D:/mysql/3380/logs/mysql-bin&quot; 指定主库serverid server-id=380 指定同步的数据库，如果不指定则同步全部数据库 我们已经创建一个数据叫taotao binlog-do-db=taotao 执行SQL语句查询状态： show master status; File:mysql-bin.000007：二进制文件；Positiion:120：位置，从哪个位置开始作同步；需要记录下Position值，需要在从库中设置同步起始值。Binlog_Do_DB:taotao：需要同步的数据库。 从库配置在my.ini修改：#指定serverid，只要不重复即可，从库也只有这一个配置，其他都在SQL语句中操作server-id=381 以下执行SQL： CHANGE MASTER TO master_host = &apos;127.0.0.1&apos;, master_user = &apos;root&apos;, master_password = &apos;root&apos;, master_port = 3380, master_log_file = &apos;mysql-bin.000007&apos;, master_log_pos = 120; #启动slave同步 START SLAVE; #查看同步状态 SHOW SLAVE STATUS; Slave_IO_Running和Slave_SQL_Runnimg都为Yes表示同步设置成功。现在是有问题的 查看从库的错误日志D:\mysql\3381\logs\mysql.err.log： [ERROR] Slave I/O: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server UUIDs; these UUIDs must be different for replication to work. Error_code: 1593 Mysql的UUID相同了，因为我们上面是复制过来的。 打开D:\mysql\3381\data\data\auto.cnf文件： [auto] server-uuid=d71ec2ee-65ba-11e5-a4e3-000c29deb96f 随便改下，不相同即可。重启3381的服务，查看Slave_IO_Running和Slave_SQL_Runnimg都为Yes 测试：分别打开主库，从库；修改主库（写库）数据，保存；查看从库数据是否有同步过去。。。。。。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Redis 3.x主从复制（读写分离）]]></title>
      <url>%2F2017%2F04%2F08%2FRedis%203.x%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%EF%BC%88%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%EF%BC%89%2F</url>
      <content type="text"><![CDATA[Redsi3.x以后，提供了真正的集群，而不是像2.x只能使用分片的集群了(分片式集群是有问题的，但也有一定的应用)。windows下目前没的提供3.0的版本的redis，所以我们在linux下安装redis，做集群的配置，需要对linux有所熟悉。 安装和配置创建安装目录，下载redis安装文件，解压缩，编译，安装 [root@localhost ~]# mkdir /usr/local/src/redis [root@localhost ~]# cd /usr/local/src/redis/ [root@localhost redis]# wget http://download.redis.io/releases/redis-3.2.6.tar.gz [root@localhost redis]# tar -xvf redis-3.2.6.tar.gz [root@localhost redis]# cd redis-3.2.6 [root@localhost redis]# make [root@localhost redis]# make install 到此安装完毕。redis的启动，停止 redis-server // 启动redis服务 redis-cli // 连接erdis服务 redis-cli shutdown // 关闭服务 Redis的主从复制（读写分离） 避免单点故障满足读多写少的应用场景。对缓存而言，读多写少，在Redis中优其重要。 我们使用Master/Slave的结构：安装一个redis，启动3个实例(6379、6380、6381) 在/usr/local/src/redis/redis-3.2.6目录下创建一个redis目录，这个redis目录下创建3个目录，一个作为master(6379)，两个作为slave(6380、6381)。 [root@localhost redis]# pwd /usr/local/src/redis/redis-3.2.6/redis 创建master-6379目录，复制 redis.conf到该目录下 [root@localhost redis]# mkdir 6379 [root@localhost redis]# cd 6379/ [root@localhost 6379]# cp /usr/local/src/redis/redis-3.2.6/redis.conf ./ [root@localhost 6379]# ll 总计 48 -rw-r--r-- 1 root root 46695 01-08 15:30 redis.conf 编辑redis.conf文件 daemonize yes # 设置为后台运行 pidfile /var/run/redis_6379.pid # 记录redis运行的进程号，每个端口对应的文件是不一样的 maxmemory 200m # redis最大内存 保存退出，后台启动redis，指定redis.conf文件 [root@localhost 6379]# redis-server ./redis.conf [root@localhost 6379]# [root@localhost 6379]# redis-cli 127.0.0.1:6379&gt; ping PONG 127.0.0.1:6379&gt; 创建6380(slave)和6381(slave)。直接复制6379(master)，修改配置文件，将6379全部替换成6380 [root@localhost redis]# ll 总计 4 drwxr-xr-x 2 root root 4096 01-08 15:46 6379 [root@localhost redis]# cp 6379/ 6380 -R [root@localhost redis]# cp 6379/ 6381 -R [root@localhost redis]# ll 总计 12 drwxr-xr-x 2 root root 4096 01-08 15:46 6379 drwxr-xr-x 2 root root 4096 01-08 15:47 6380 drwxr-xr-x 2 root root 4096 01-08 15:48 6381 [root@localhost 6380]# vim redis.conf :%s/6379/6380/g # 将6379全部替换成6380 6381的redis.conf同样也替换成6381 启动3个redis实例： [root@localhost redis]# redis-server ./6379/redis.conf [root@localhost redis]# redis-server ./6380/redis.conf [root@localhost redis]# redis-server ./6381/redis.conf [root@localhost redis]# ps -ef | grep redis root 12583 1 0 16:04 ? 00:00:00 redis-server 127.0.0.1:6379 root 12587 1 0 16:04 ? 00:00:00 redis-server 127.0.0.1:6380 root 12591 1 0 16:04 ? 00:00:00 redis-server 127.0.0.1:6381 root 12601 12413 0 16:07 pts/3 00:00:00 grep redis 设置主从两种方式可以设置主从 在redis.conf中设置slaveofslaveof masterip masterport 使用redis-cli客户端连接到redis服务，执行slaveof命令slaveof masterip masterport第二种方式重启服务以后，将失去主从复制关系。 分别设置6380、6381两个Slave开始主从模式 slaveof 127.0.0.1 6379 查看主从关系： [root@localhost redis]# redis-cli 127.0.0.1:6379&gt; info replication # Replication role:master connected_slaves:2 slave0:ip=127.0.0.1,port=6380,state=online,offset=71,lag=1 slave1:ip=127.0.0.1,port=6381,state=online,offset=71,lag=1 master_repl_offset:71 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:2 repl_backlog_histlen:70 127.0.0.1:6379&gt; 当前角色是master(role:master)，有两个从的连接(connected_slaves:2)，分别是slave0:ip=127.0.0.1,port=6380,state=online,offset=71,lag=1和slave1:ip=127.0.0.1,port=6381,state=online,offset=71,lag=1 从6380(Slave)查看主从关系 [root@localhost redis]# redis-cli -p 6380 127.0.0.1:6380&gt; info replication # Replication role:slave master_host:127.0.0.1 master_port:6379 master_link_status:up master_last_io_seconds_ago:4 master_sync_in_progress:0 slave_repl_offset:43 slave_priority:100 slave_read_only:1 connected_slaves:0 master_repl_offset:0 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 127.0.0.1:6380&gt; 测试：主库/写库(master)中写入数据，查看从库/读库（Slave）中的数据情况 主库： [root@localhost redis]# redis-cli -p 6379 127.0.0.1:6379&gt; set name leilei OK 从库: [root@localhost redis]# redis-cli -p 6380 127.0.0.1:6380&gt; keys * (empty list or set) 127.0.0.1:6380&gt; keys * 1) &quot;name&quot; 从库是不能写入数据的 127.0.0.1:6380&gt; set test aaa (error) READONLY You can&apos;t write against a read only slave. 还有一种结构是主-从-从，从第二个从库开始，作为下级的主库（一般也是只读的） 主从复制过程原理： 当从库与主库建立Master/Slave关系后，会向主库发送sync命令； 主库接收到sync命令以后，会在后台保存快照（RDB持久化方式），并将期间接收到的命令缓存起来； 当快照完成后，主库会将快照文件和所有缓存的写命令发送给从库； 从库接收到后，载入快照文件并且执行接收到的缓存命令，保持数据一致； 之后，主库每当接收到写命令时就会发送给从库，保存数据一致。 无磁盘复制redis从2.8.18实现了无磁盘复制功能（实验阶段），当磁盘出现IO性能问题时，主库在与从库复制数据时，不会将快照存储磁盘上，而是直接通过网络发送给从库。通过配置开启： repl-diskless-sync yes 复制架构中出现宕机情况如果在主从复制架构中出现宕机的情况，需要分情况看： 从库宕机a) 这个相对而言比较简单，在Redis中从库重新启动后会自动加入到主从架构中，自动完成同步数据；b) 问题？ 如果从库在断开期间，主库的变化不大，从库再次启动后，主库依然会将所有的数据做RDB操作吗？还是增量更新？（从库有做持久化的前提下）不会将所有数据做RDB的，因为在Redis2.8版本后就实现了，主从断线后恢复的情况下实现增量复制。 主库宕机a) 这个相对而言就会复杂一些，需要以下2步才能完成第一步，在从数据库中执行SLAVEOF NO ONE命令，断开主从关系并且提升为主库继续服务；第二步，将主库重新启动后，执行SLAVEOF命令，将其设置为其他库的从库，这时数据就能更新回来；b) 这个手动完成恢复的过程其实是比较麻烦的并且容易出错，有没有好办法解决呢？当前有的，Redis提供的哨兵（sentinel）的功能。 哨兵（sentinel）什么是哨兵顾名思义，哨兵的作用就是对Redis的系统的运行情况的监控，它是一个独立进程。它的功能有2个： 监控主库和从库是否运行正常； 数据出现故障后自动将从库转化为主库； 原理单个哨兵的架构： 多个哨兵的架构：多个哨兵，不仅同时监控主从库，而且哨兵之间互为监控。 配置哨兵启动哨兵进程首先需要创建哨兵配置文件： vim sentinel.conf 输入内容： sentinel monitor taotaoMaster 127.0.0.1 6379 1 说明：taotaoMaster：监控主库的名称，自定义即可，可以使用大小写字母和“.-_”符号127.0.0.1：监控的主库的IP6379：监控的主库的端口1：最低通过票数 启动哨兵进程： redis-sentinel ./sentinel.conf 由上图可以看到：1、 哨兵已经启动，它的id为9059917216012421e8e89a4aa02f15b75346d2b72、 为master库添加了一个监控3、 发现了2个slave（由此可以看出，哨兵无需配置slave，只需要指定master，哨兵会自动发现slave） 从库宕机：kill掉从库进程后，30秒后哨兵的控制台输出： 2989:X 05 Jun 20:09:33.509 # +sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 6379 说明已经监控到slave宕机了，那么，如果我们将3380端口的redis实例启动后，会自动加入到主从复制吗？ 2989:X 05 Jun 20:13:22.716 * +reboot slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 63792989:X 05 Jun 20:13:22.788 # -sdown slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 6379 可以看出，slave从新加入到了主从复制中。-sdown：说明是恢复服务。 主库宕机哨兵控制台打印出如下信息：2989:X 05 Jun 20:16:50.300 # +sdown master taotaoMaster 127.0.0.1 6379 说明master服务已经宕机2989:X 05 Jun 20:16:50.300 # +odown master taotaoMaster 127.0.0.1 6379 #quorum 1/12989:X 05 Jun 20:16:50.300 # +new-epoch 12989:X 05 Jun 20:16:50.300 # +try-failover master taotaoMaster 127.0.0.1 6379 开始恢复故障2989:X 05 Jun 20:16:50.304 # +vote-for-leader 9059917216012421e8e89a4aa02f15b75346d2b7 1 投票选举哨兵leader，现在就一个哨兵所以leader就自己2989:X 05 Jun 20:16:50.304 # +elected-leader master taotaoMaster 127.0.0.1 6379 选中leader2989:X 05 Jun 20:16:50.304 # +failover-state-select-slave master taotaoMaster 127.0.0.1 6379 选中其中的一个slave当做master2989:X 05 Jun 20:16:50.357 # +selected-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ taotaoMaster 127.0.0.1 6379 选中63812989:X 05 Jun 20:16:50.357 +failover-state-send-slaveof-noone slave 127.0.0.1:6381 127.0.0.1 6381 @ taotaoMaster 127.0.0.1 6379 发送slaveof no one命令2989:X 05 Jun 20:16:50.420 +failover-state-wait-promotion slave 127.0.0.1:6381 127.0.0.1 6381 @ taotaoMaster 127.0.0.1 6379 等待升级master2989:X 05 Jun 20:16:50.515 # +promoted-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ taotaoMaster 127.0.0.1 6379 升级6381为master2989:X 05 Jun 20:16:50.515 # +failover-state-reconf-slaves master taotaoMaster 127.0.0.1 63792989:X 05 Jun 20:16:50.566 +slave-reconf-sent slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 63792989:X 05 Jun 20:16:51.333 +slave-reconf-inprog slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 63792989:X 05 Jun 20:16:52.382 +slave-reconf-done slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 63792989:X 05 Jun 20:16:52.438 # +failover-end master taotaoMaster 127.0.0.1 6379故障恢复完成2989:X 05 Jun 20:16:52.438 # +switch-master taotaoMaster 127.0.0.1 6379 127.0.0.1 6381 主数据库从6379转变为63812989:X 05 Jun 20:16:52.438 +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster 127.0.0.1 6381 添加6380为6381的从库2989:X 05 Jun 20:16:52.438 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster 127.0.0.1 6381 添加6379为6381的从库2989:X 05 Jun 20:17:22.463 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster 127.0.0.1 6381 发现6379已经宕机，等待6379的恢复 可以看出，目前，6381位master，拥有一个slave为6380. 接下来，我们恢复6379查看状态：2989:X 05 Jun 20:35:32.172 # -sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster 127.0.0.1 6381 6379已经恢复服务2989:X 05 Jun 20:35:42.137 * +convert-to-slave slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster 127.0.0.1 6381 将6379设置为6381的slave 配置多个哨兵 vim sentinel.conf 输入内容： sentinel monitor taotaoMaster 127.0.0.1 6381 2 sentinel monitor taotaoMaster2 127.0.0.1 6381 1 3451:X 05 Jun 21:05:56.083 # +sdown master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.083 # +odown master taotaoMaster2 127.0.0.1 6381 #quorum 1/13451:X 05 Jun 21:05:56.083 # +new-epoch 13451:X 05 Jun 21:05:56.083 # +try-failover master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.086 # +vote-for-leader 3f020a35c9878a12d2b44904f570dc0d4015c2ba 13451:X 05 Jun 21:05:56.086 # +elected-leader master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.086 # +failover-state-select-slave master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.087 # +sdown master taotaoMaster 127.0.0.1 63813451:X 05 Jun 21:05:56.189 # +selected-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.189 +failover-state-send-slaveof-noone slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:56.252 +failover-state-wait-promotion slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:57.145 # +promoted-slave slave 127.0.0.1:6380 127.0.0.1 6380 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:57.145 # +failover-state-reconf-slaves master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:57.234 +slave-reconf-sent slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:58.149 +slave-reconf-inprog slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:58.149 +slave-reconf-done slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:58.203 # +failover-end master taotaoMaster2 127.0.0.1 63813451:X 05 Jun 21:05:58.203 # +switch-master taotaoMaster2 127.0.0.1 6381 127.0.0.1 63803451:X 05 Jun 21:05:58.203 +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ taotaoMaster2 127.0.0.1 63803451:X 05 Jun 21:05:58.203 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ taotaoMaster2 127.0.0.1 6380]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring AMQP对RabbitMQ的支持]]></title>
      <url>%2F2017%2F03%2F21%2Fspring-AMQP%E5%AF%B9RabbitMQ%E7%9A%84%E6%94%AF%E6%8C%81%2F</url>
      <content type="text"><![CDATA[AMQP(Adanced Message Queuing Protocol)：高级消息队列协议。是一个异步消息传递所使用的应用层协议规范。AMQP客户端能够无视消息的来源任意发送和接受消息。spirng-AMQP简化了对MQ的使用，目前还只是支持RabbitMQ。与spirng整合使用:消费者：123456public class Foo &#123; //具体执行业务的方法 public void listen(String foo) &#123; System.out.println("消费者： " + foo); &#125;&#125; 生产者：1234567891011public class SpringMain &#123; public static void main(final String... args) throws Exception &#123; AbstractApplicationContext ctx = new ClassPathXmlApplicationContext("classpath:spring/rabbitmq-context.xml"); // RabbitMQ模板 RabbitTemplate template = ctx.getBean(RabbitTemplate.class); // 发送消息 template.convertAndSend("Hello, world!"); Thread.sleep(1000);// 休眠1秒 ctx.destroy(); // 容器销毁 &#125;&#125; 代码很简单，那么所有关联关系，队列，交换机等，都在spring配置文件中处理： 定义RabbitMQ的连接工厂connectionFactory，连接到RabbitMQ服务器； 定义Rabbit模板amqpTemplate，该模板就是操作RabbitMQ的入口，用来发送消息等 Rabbit模板amqpTemplate所依赖的内容有：连接工厂connectionFactory，交换机fanoutExchange 将队列myQueue绑定到交换机fanoutExchange 定义消费者foo来监听消息，一有消息马上接受处理。123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:rabbit="http://www.springframework.org/schema/rabbit" xsi:schemaLocation="http://www.springframework.org/schema/rabbit http://www.springframework.org/schema/rabbit/spring-rabbit-1.4.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.1.xsd"&gt; &lt;!-- 定义RabbitMQ的连接工厂 --&gt; &lt;rabbit:connection-factory id="connectionFactory" host="127.0.0.1" port="5672" username="taotao" password="taotao" virtual-host="/taotao" /&gt; &lt;!-- 定义Rabbit模板，指定连接工厂以及定义exchange --&gt; &lt;rabbit:template id="amqpTemplate" connection-factory="connectionFactory" exchange="fanoutExchange" /&gt; &lt;!-- &lt;rabbit:template id="amqpTemplate" connection-factory="connectionFactory" exchange="fanoutExchange" routing-key="foo.bar" /&gt; --&gt; &lt;!-- MQ的管理，包括队列、交换器等 --&gt; &lt;rabbit:admin connection-factory="connectionFactory" /&gt; &lt;!-- 定义队列，自动声明 --&gt; &lt;rabbit:queue name="myQueue" auto-declare="true" durable="false" /&gt; &lt;!-- 定义交换器，自动声明 --&gt; &lt;rabbit:fanout-exchange name="fanoutExchange" auto-declare="true" durable="false"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue="myQueue" /&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:fanout-exchange&gt; &lt;!-- &lt;rabbit:topic-exchange name="myExchange"&gt; &lt;rabbit:bindings&gt; &lt;rabbit:binding queue="myQueue" pattern="foo.*" /&gt; &lt;/rabbit:bindings&gt; &lt;/rabbit:topic-exchange&gt; --&gt; &lt;!-- 队列监听 --&gt; &lt;rabbit:listener-container connection-factory="connectionFactory"&gt; &lt;rabbit:listener ref="foo" method="listen" queue-names="myQueue" /&gt; &lt;/rabbit:listener-container&gt; &lt;bean id="foo" class="com.belongtou.rabbitmq.spring.Foo" /&gt;&lt;/beans&gt;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[hexo d 发布到github时，报错：fatal: The remote end hung up unexpectedly]]></title>
      <url>%2F2017%2F03%2F16%2Fhexo-d-%E5%8F%91%E5%B8%83%E5%88%B0github%E6%97%B6%EF%BC%8C%E6%8A%A5%E9%94%99%EF%BC%9Afatal-The-remote-end-hung-up-unexpectedly%2F</url>
      <content type="text"><![CDATA[发布博客内容到github上时，报以下错误：fatal: The remote end hung up unexpectedly，现在也没明白是怎么回事…….1234567891011121314151617181920212223242526272829303132333435363738$ hexo dINFO Deploying: gitINFO Clearing .deploy_git folder...INFO Copying files from public folder...[master 045499c] Site updated: 2016-12-29 18:49:47 1 file changed, 1 insertion(+), 1 deletion(-)fatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyerror: RPC failed; curl 52 Empty reply from serverEverything up-to-dateFATAL Something&apos;s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.htmlError: fatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyerror: RPC failed; curl 52 Empty reply from serverEverything up-to-date at ChildProcess.&lt;anonymous&gt; (D:\blog\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at ChildProcess.cp.emit (D:\blog\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:850:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:215:5)FATAL fatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyerror: RPC failed; curl 52 Empty reply from serverEverything up-to-dateError: fatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyerror: RPC failed; curl 52 Empty reply from serverEverything up-to-date at ChildProcess.&lt;anonymous&gt; (D:\blog\node_modules\hexo-util\lib\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at ChildProcess.cp.emit (D:\blog\node_modules\cross-spawn\lib\enoent.js:40:29) at maybeClose (internal/child_process.js:850:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:215:5) 按网上的童鞋的方法，配置了个参数 git config http.postBuffer 524288000 或者打开工程目录/.git/config文件，在最后加一项 [http] postBuffer = 524288000 config文件内容如下： [core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true [remote &quot;origin&quot;] url = https://github.com/leileiyuan/hexoSource.git fetch = +refs/heads/*:refs/remotes/origin/* [branch &quot;master&quot;] remote = origin merge = refs/heads/master [gui] wmstate = normal geometry = 835x475+100+100 185 214 [http] postBuffer = 524288000 再重新发布，就可以了。 原因未知，一脸黑线…….原因未知，一脸黑线…….原因未知，一脸黑线…….]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RabbitMQ配置用户角色/权限]]></title>
      <url>%2F2017%2F02%2F25%2FRabbitMQ%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E8%A7%92%E8%89%B2-%E6%9D%83%E9%99%90%2F</url>
      <content type="text"><![CDATA[在RabbitMQ中添加用户，配置权限，设置Virtual Hosts 用户角色说明 超级管理员(administrator)可登陆管理控制台，可查看所有的信息，并且可以对用户，策略(policy)进行操作。 监控者(monitoring)可登陆管理控制台，同时可以查看rabbitmq节点的相关信息(进程数，内存使用情况，磁盘使用情况等) 策略制定者(policymaker)可登陆管理控制台, 同时可以对policy进行管理。但无法查看节点的相关信息(上图红框标识的部分)。 普通管理者(management)仅可登陆管理控制台，无法看到节点信息，也无法对策略进行管理。 其他无法登陆管理控制台，通常就是普通的生产者和消费者。 添加用户角色我们添加一个用户，设置角色为administrator 创建Virtual Hosts 设置权限 现在就可以使用我们新增加的用户来管理维护MQ了。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RabbitMQ在windows下的安装问题]]></title>
      <url>%2F2017%2F02%2F25%2FRabbitMQ%E5%9C%A8windows%E4%B8%8B%E7%9A%84%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[RabbitMQ在windows安装，有些问题会导致安装失败，安装的注意事项： 使用默认的安装路径 系统用户名必须是英文 计算机名必须是英文 或者 直接在linux 中安装。 安装过程有错误，忽略 安装完成后，系统服务中会有RabbitMQ的服务在 找到RabbitMQ的安装目录，启动管理插件rabbitmq-plugins enable rabbitmq_management 在浏览器中输入地址查看：http://127.0.0.1:15672/。使用默认的账户登录：guest/ guest 登录成功才算安装成功]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[RebbitMQ5种模式的使用]]></title>
      <url>%2F2017%2F02%2F24%2FRebbitMQ5%E7%A7%8D%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
      <content type="text"><![CDATA[MQ(Message Quequ)：消息队列是应用程序和应用程序之间的通信方法。RabbitMQ是一个开源的，基于AMQP(Advanced Mseeage Queuing Protocol)的消息队列。 RabbitMQ官网http://www.rabbitmq.com提供了6种消息队列1 “Hello World!”简单队列生产者与消费者一对一P：Producer，生产者；C：Consumer，消费者 简单队列生产者：1234567891011121314151617181920212223package com.belongtou.rabbitmq.simple;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import cn.itcast.rabbitmq.util.ConnectionUtil;/** 生产者 */public class Producer &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] args) throws Exception &#123; // 获取MQ连接及通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明（创建）队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 发送消息 String message = "Hello World!"; channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); // 关闭通道和连接 channel.close(); connection.close(); &#125;&#125; 简单队列消费者：12345678910111213141516171819202122232425262728package com.belongtou.rabbitmq.simple;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.QueueingConsumer;import cn.itcast.rabbitmq.util.ConnectionUtil;/** 消费者 */public class Consumer &#123; private final static String QUEUE_NAME = "hello"; public static void main(String[] args) throws Exception &#123; // 获取连接及通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列 channel.basicConsume(QUEUE_NAME, true, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" [x] Received '" + message + "'"); &#125; &#125;&#125; 2 Work queuesWork模式的队列是一个生产者对应多个消费者，消息是竞争的，谁抢到消息算谁的为了说明问题，采用重复代码来提供两个消费者。设置的两个消费者的休眠时间一个长一个短。也就是说一个任务可能执行多，一个任务可能执行的少，来争抢消息。生产者：12345678910111213141516171819202122232425/** 生产者 */public class Producer &#123; private final static String QUEUE_NAME = "queue_work"; public static void main(String[] args) throws Exception &#123; // 获取MQ连接及通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明（创建）队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 发送消息 for (int i = 0; i &lt; 50; i++) &#123; // 消息内容 String message = "" + i; channel.basicPublish("", QUEUE_NAME, null, message.getBytes()); System.out.println(" [x] Sent '" + message + "'"); Thread.sleep(i * 10); &#125; // 关闭通道和连接 channel.close(); connection.close(); &#125;&#125; 消费者一：1234567891011121314151617181920212223242526272829/** 消费者一 */public class Consumer &#123; private final static String QUEUE_NAME = "queue_work"; public static void main(String[] args) throws Exception &#123; // 获取连接及通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 同一时刻服务器只会发一条消息给消费者 //channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列,设置为false，手动返回状态 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody(), "UTF-8"); System.out.println(" Consumer111 [x] Received '" + message + "'"); // 休眠10毫秒 Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 消费者二：123456789101112131415161718192021222324252627282930/** 消费者二 */public class Consumer2 &#123; private final static String QUEUE_NAME = "queue_work"; public static void main(String[] args) throws Exception &#123; // 获取连接及通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 同一时刻服务器只会发一条消息给消费者 //channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列,设置为false，手动返回状态 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody(), "UTF-8"); System.out.println("Consumer2 [x] Received '" + message + "'"); // 休眠1秒 Thread.sleep(1000); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 运行结果：消费者一： Consumer111 [x] Received &apos;1&apos; Consumer111 [x] Received &apos;3&apos; Consumer111 [x] Received &apos;5&apos; 消费者二： Consumer2 [x] Received &apos;0&apos; Consumer2 [x] Received &apos;2&apos; Consumer2 [x] Received &apos;4&apos; Consumer2 [x] Received &apos;6&apos; Consumer2 [x] Received &apos;8&apos; 实际结果是，消费者一和消费者二，交替获取消息。并非”能者多劳”，我们要对通道设置一个值，同一时刻只发一条消息给消费者： // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); 如此，消息便会产生争抢。 消息确认消费者从队列中获取消息，服务端如何知道消息已经被消费呢。有两种确定模式：自动确认：只要消息从队列中获取，无论消费者获取到消息是否成功消费，都认为消息已经成功消费。手动确认：消费从队列中获取消息后，服务器将该消息标记为不可用状态，等待消费者的反馈，如果消息者一直没有反馈，那么该消息一直处于不可用状态。 手动模式：消费者收到消息，给服务器一个反馈。123456789101112131415// 定义队列的消费者QueueingConsumer consumer = new QueueingConsumer(channel);// 监听队列,设置为false，手动返回完成channel.basicConsume(QUEUE_NAME, false, consumer);// 获取消息while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody(), "UTF-8"); System.out.println("Consumer2 [x] Received '" + message + "'"); // 休眠1秒 Thread.sleep(1000); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);&#125; 自动模式：1234// 定义队列的消费者QueueingConsumer consumer = new QueueingConsumer(channel);// 监听队列channel.basicConsume(QUEUE_NAME, true, consumer); 3 Publish/Subscribe订阅模式。生产者把消息发送到交换机，队列绑定到交换机上，消费者即可通过队列获取消息，可以达到一个消息被多个消息者获取的目的，不需要再从队列中获取消息，解除队列与交换机的绑定关系即可。X(Exchanges)：交换机 消息发送到交换机，没有队列绑定到交换机时，消息将丢失。交换机没有存储消息的能力。 场景：商品进行了添加或更新，需要通知给某前台系统刷新缓存，通知给某搜索系统更新数据刷新缓存生产者：12345678910111213141516171819public class Send &#123; private final static String EXCHANGE_NAME = "test_exchange_fanout"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明exchange channel.exchangeDeclare(EXCHANGE_NAME, "fanout"); // 消息内容 String message = "商品已经被更新，id=1001"; channel.basicPublish(EXCHANGE_NAME, "", null, message.getBytes()); System.out.println(" 后台系统： '" + message + "'"); channel.close(); connection.close(); &#125;&#125; 消费者一：12345678910111213141516171819202122232425262728293031323334public class Recv &#123; private final static String QUEUE_NAME = "test_queue_ps_1"; private final static String EXCHANGE_NAME = "test_exchange_fanout"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(" 前台系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 消费者二：12345678910111213141516171819202122232425262728293031323334public class Recv2 &#123; private final static String QUEUE_NAME = "test_queue_ps_2"; private final static String EXCHANGE_NAME = "test_exchange_fanout"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, ""); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println("搜索系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 运行结果：消费者一和消费者二 都会收到该消息 后台系统： &apos;商品已经被更新，id=1001&apos;//生产者 搜索系统： &apos;商品已经被更新，id=1001&apos; 前台系统： &apos;商品已经被更新，id=1001&apos; 交换机类型：Fanout Exchange订阅模式中，这种交换机叫做Fanout Exchange， 不处理路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。不设置路由key：1234567891011Channel channel = connection.createChannel(); channel.exchangeDeclare("exchangeName", "fanout"); //direct fanout topic channel.queueDeclare("queueName"); channel.queueBind("queueName", "exchangeName", "routingKey"); channel.queueDeclare("queueName1"); channel.queueBind("queueName1", "exchangeName", "routingKey1"); byte[] messageBodyBytes = "hello world".getBytes(); //路由键需要设置为空 channel.basicPublish("exchangeName", "", MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 4 Routing路由模式。当消费者绑定队列到交换机时，指定路由key。如下图，消费者一将队列绑定到交换机时，指定的路由为error，消费者二将队列绑定到交换机时，指定的路由为是info、error、warning，那么不同的消息可以发送给特定的消费者 生产者：生产者将路由key为”inster”的消息发送到交换机12345678910111213141516171819public class Send &#123; private final static String EXCHANGE_NAME = "test_exchange_direct"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明exchange channel.exchangeDeclare(EXCHANGE_NAME, "direct"); // 消息内容 String message = "商品删除，id=1002"; channel.basicPublish(EXCHANGE_NAME, "insert", null, message.getBytes()); System.out.println(" 后台系统： '" + message + "'"); channel.close(); connection.close(); &#125;&#125; 消费者一：消费者一绑定队列到交换机，获取路由key为”update”或”delete”的消息。此时没有获取到消息，生产者发送的消息，路由key为”insert”，所以消费者一接受不到消息。1234567891011121314151617181920212223242526272829303132333435public class Recv &#123; private final static String QUEUE_NAME = "test_queue_direct_1"; private final static String EXCHANGE_NAME = "test_exchange_direct"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "delete"); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(" 前台系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 消费者二：消费者二可以接受到由生产者发送的消息，路由key都包含有”insert”123456789101112131415161718192021222324252627282930313233343536public class Recv2 &#123; private final static String QUEUE_NAME = "test_queue_direct_2"; private final static String EXCHANGE_NAME = "test_exchange_direct"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "insert"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "delete"); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(" 搜索系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 交换机类型：Direct Exchange路由模式中的交换机叫做Direct Exchange，该交换处理路由键。需要将一个队列绑定到交换机上，要求该消息与一个特定的路由键完全匹配。这是一个完整的匹配。如果一个队列绑定到该交换机上要求路由键 “insert”，则只有被标记为“insert”的消息才被转发，不会转发update，也不会转发delete，只会转发insert。处理路由key:12345678Channel channel = connection.createChannel(); channel.exchangeDeclare("exchangeName", "direct"); //direct fanout topic channel.queueDeclare("queueName"); channel.queueBind("queueName", "exchangeName", "routingKey"); byte[] messageBodyBytes = "hello world".getBytes(); //需要绑定路由键 channel.basicPublish("exchangeName", "routingKey", MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 5 Topics通配符模式。#：匹配一个或多个词；*：匹配一个词符号”#”匹配一个或多个词，符号”*“匹配不多不少一个词。因此“audit.#”能够匹配到“audit.irs.corporate”，但是“audit.*” 只会匹配到“audit.irs”。 消费者一获取的消息只能是”item.update” 、”item.delete”；消费者二获取的消息只能是以”item.”开头的生产者：12345678910111213141516171819public class Send &#123; private final static String EXCHANGE_NAME = "test_exchange_topic"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明exchange channel.exchangeDeclare(EXCHANGE_NAME, "topic"); // 消息内容 String message = "商品删除，id=1003"; channel.basicPublish(EXCHANGE_NAME, "item.delete", null, message.getBytes()); System.out.println(" 后台系统： '" + message + "'"); channel.close(); connection.close(); &#125;&#125; 消费者一：1234567891011121314151617181920212223242526272829303132333435public class Recv &#123; private final static String QUEUE_NAME = "test_queue_topic_1"; private final static String EXCHANGE_NAME = "test_exchange_topic"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.update"); channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.delete"); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(" 前台系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 消费者二：12345678910111213141516171819202122232425262728293031323334public class Recv2 &#123; private final static String QUEUE_NAME = "test_queue_topic_2"; private final static String EXCHANGE_NAME = "test_exchange_topic"; public static void main(String[] argv) throws Exception &#123; // 获取到连接以及mq通道 Connection connection = ConnectionUtil.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); // 绑定队列到交换机 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, "item.#"); // 同一时刻服务器只会发一条消息给消费者 channel.basicQos(1); // 定义队列的消费者 QueueingConsumer consumer = new QueueingConsumer(channel); // 监听队列，手动返回完成 channel.basicConsume(QUEUE_NAME, false, consumer); // 获取消息 while (true) &#123; QueueingConsumer.Delivery delivery = consumer.nextDelivery(); String message = new String(delivery.getBody()); System.out.println(" 搜索系统： '" + message + "'"); Thread.sleep(10); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;&#125; 交换机类型：Topic Exchange将路由键和某模式进行匹配。此时队列需要绑定在一个模式上。1234567Channel channel = connection.createChannel(); channel.exchangeDeclare("exchangeName", "topic"); //direct fanout topic channel.queueDeclare("queueName"); channel.queueBind("queueName", "exchangeName", "routingKey.*"); byte[] messageBodyBytes = "hello world".getBytes(); channel.basicPublish("exchangeName", "routingKey.one", MessageProperties.PERSISTENT_TEXT_PLAIN, messageBodyBytes); 6 RPC远程调用，这种模式，严格意义上来讲，不算是消息队列。可以使用专门的RPC服务框架(比如dubbo：http://dubbo.io/) 获取连接的类 ConnectionUtil:1234567891011121314151617public class ConnectionUtil &#123; public static Connection getConnection() throws Exception &#123; // 定义连接工厂 ConnectionFactory factory = new ConnectionFactory(); // 设置服务地址 factory.setHost("localhost"); // 端口 factory.setPort(5672); // 设置账号信息，用户名、密码、vhost factory.setVirtualHost("/taotao"); factory.setUsername("taotao"); factory.setPassword("taotao"); // 通过工程获取连接 Connection connection = factory.newConnection(); return connection; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[jdk的Fork/Join框架]]></title>
      <url>%2F2016%2F12%2F25%2Fjdk%E7%9A%84Fork-Join%E6%A1%86%E6%9E%B6%2F</url>
      <content type="text"><![CDATA[jkd7提供了一个用于并行执行任务的框架，是把一个大任务分割成若干个小任务，将小任务的执行结果汇总起来，得到大任务的结果。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ForkJoinTaskDemo &#123; public static void main(String[] args) throws Exception &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); CountTask task = new CountTask(1, 5); Future&lt;Integer&gt; result = forkJoinPool.submit(task); System.out.println("1-5相加结果：" + result.get()); CountTask task2 = new CountTask(1, 100); Future&lt;Integer&gt; result2 = forkJoinPool.submit(task2); System.out.println("1-100相加结果：" + result2.get()); System.out.println("thread main end!"); &#125;&#125;public class CountTask extends RecursiveTask&lt;Integer&gt; &#123; private static int selitSize = 2; private int start, end; public CountTask(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; int sum = 0; // 如果任务不需要再拆分 就开始计算 boolean canCompute = (end - start) &lt;= selitSize; if (canCompute) &#123; for (int i = start; i &lt;= end; i++) &#123; sum += i; &#125; &#125; else &#123; // 拆分成两个子任务 int middle = (start + end) / 2; CountTask firstTask = new CountTask(start, middle); CountTask secondTask = new CountTask(middle + 1, end); // 开始执行任务 firstTask.fork(); secondTask.fork(); // 获取第一个任务的执行结果，得不到结果，此线程不会往下面执行。 Integer firstResult = firstTask.join(); Integer secoundResult = secondTask.join(); // 合并两个儿子的执行结果 sum = firstResult + secoundResult; &#125; return sum; &#125;&#125; 执行结果： 1-5相加结果：15 1-100相加结果：5050 thread main end! ForkJoinTask与一般的任务的主要区别在于它需要实现compute方法，在这个方法，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果任务不足够小，就必须分割成两个子任务，每个子任务在调用fork方法时，又会进入compute方法，当前子任务如果不需要再继续分割，则执行当前子任务并返回结果。使用join方法会等待子任务执行完成并得到其结果。 fork()：这个方法决定了ForkJoinTask的异步执行，凭借这个方法可以创建新的任务。join()：该方法负责在计算完成后返回结果，因此允许一个任务等待另一个任务执行完成。 Fork/Join的执行逻辑是这样：第一步分割任务。需要有一个fork来把大任务分割成子任务，分割后的任务可能很大，还需要继续分割，直到分割的子任务足够小；分割的任务都放在当前线程所维护的双端队列中，进入队列的头部。第二步执行任务并得到结果。执行任务时，几个启动线程从队列中获取任务并执行，子任务执行完的结果统一放在一个队列里，启动一个线程从队列里拿数据，合并这些数据。 通常情况下我们不需要直接继承ForkJionTask，只需要继承它的子类，重载protected void coumpute()方法。ForkJionTask提供了两个子类：RecursiveAction：用于没有返回结果的任务。RecursiveTask：用于有返回结果的任务。 使用Fork/Jion统计某盘符下的文件数量：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class ForkJoinTaskDemo &#123; private static final String DIR = "D:/creditease"; public static void main(String[] args) throws Exception &#123; CountingTask task = new CountingTask(Paths.get(DIR)); Integer count = new ForkJoinPool().invoke(task); System.out.println(DIR + "下面总文件数量：" + count); &#125;&#125;public class CountingTask extends RecursiveTask&lt;Integer&gt;&#123; private Path dir; public CountingTask(Path dir) &#123; this.dir = dir; &#125; @Override protected Integer compute() &#123; int count = 0; // 文件数 List&lt;CountingTask&gt; subTasks = new ArrayList&lt;&gt;(); try &#123; // 读取目录dir的子路径。 DirectoryStream&lt;Path&gt; ds = Files.newDirectoryStream(dir); for (Path subPath : ds) &#123; if (Files.isDirectory(subPath, LinkOption.NOFOLLOW_LINKS)) &#123; subTasks.add(new CountingTask(subPath)); &#125; else &#123; count++; &#125; &#125; if (!subTasks.isEmpty()) &#123; // 在当前的ForkJoinPool上高度所有的子任务 for (CountingTask subTask : invokeAll(subTasks)) &#123; count += subTask.join(); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); return 0; &#125; return count; &#125;&#125; 对于树形结构的遍历处理非常适合。 简单总结下： 使用Fork/Jion模式，可以方便的实现并发任务的拆分，不需要处理各种相关事务，同步、通信之类的，仅仅关注如何划分和组合中间结果。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[springMvc 响应返回406 Not Acceptable]]></title>
      <url>%2F2016%2F12%2F17%2FspringMvc-%E5%93%8D%E5%BA%94%E8%BF%94%E5%9B%9E406-Not-Acceptable%2F</url>
      <content type="text"><![CDATA[spirngMvc请求时，响应返回406 Not Acceptable问题的分析和解决。请求地址： http://sso.taotao.com/user/yuanleilei/1.html?r=0.950404558563605 web.xml中springmvc的配置 &lt;servlet&gt; &lt;servlet-name&gt;taotao-web&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/taotao-sso-servlet.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;taotao-web&lt;/servlet-name&gt; &lt;!-- 伪静态 伪静态有利于SEO（搜索引擎优化） --&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 请求凡是以*.html的结尾的都将被springmvc拦截，都认为是springmvc的合法请求，都会进入springmvc框架中进行处理。 后台日志中,请求已接受到，并由UserController.check方法处理，创建了事务PROPAGATION_REQUIRED,ISOLATION_DEFAULT，连接到数据库jdbc:mysql://127.0.0.1:3306/taotao，执行了查询SELECT UPDATED,ID,USERNAME,EMAIL,PHONE,CREATED,PASSWORD FROM tb_user WHERE USERNAME = ?，视图解析时发生异常Resolving exception from handler...... org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation 123452016-12-17 09:56:09,804 [http-bio-8083-exec-8] [org.springframework.web.servlet.mvc.method.annotation.ExceptionHandlerExceptionResolver]-[DEBUG] Resolving exception from handler [public org.springframework.http.ResponseEntity&lt;java.lang.Boolean&gt; com.taotao.sso.controller.UserController.check(java.lang.String,java.lang.Integer)]: org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation2016-12-17 09:56:09,805 [http-bio-8083-exec-8] [org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver]-[DEBUG] Resolving exception from handler [public org.springframework.http.ResponseEntity&lt;java.lang.Boolean&gt; com.taotao.sso.controller.UserController.check(java.lang.String,java.lang.Integer)]: org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation2016-12-17 09:56:09,805 [http-bio-8083-exec-8] [org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolver]-[DEBUG] Resolving exception from handler [public org.springframework.http.ResponseEntity&lt;java.lang.Boolean&gt; com.taotao.sso.controller.UserController.check(java.lang.String,java.lang.Integer)]: org.springframework.web.HttpMediaTypeNotAcceptableException: Could not find acceptable representation2016-12-17 09:56:09,805 [http-bio-8083-exec-8] [org.springframework.web.servlet.DispatcherServlet]-[DEBUG] Null ModelAndView returned to DispatcherServlet with name &apos;taotao-web&apos;: assuming HandlerAdapter completed request handling2016-12-17 09:56:09,805 [http-bio-8083-exec-8] [org.springframework.web.servlet.DispatcherServlet]-[DEBUG] Successfully completed request 原因：响应时设置了@RequestBody，把对象转换成json返回时，缺少依赖的jar包。加入依赖包：jackson-core-asl-x.jar，jackson-mapper-asl-x.jar问题解决. ###但是。问题还是存在springmvc有个规定，html的请求不以json返回。 我们配置的web.xml中，是以html为映射的 现在有两种解决方法：1。把web.xml的映射方式改为别的，比如.do，所有依赖这个映射的url都要以*.do结尾2。加一个映射， &lt;servlet-mapping&gt; &lt;servlet-name&gt;taotao-web&lt;/servlet-name&gt; &lt;!-- 伪静态 伪静态有利于SEO（搜索引擎优化） --&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;taotao-web&lt;/servlet-name&gt; &lt;url-pattern&gt;/service/*&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 以/service开头的请求和以*.html结尾的请求，都是指向taotao-web的sevlet的。那么我们的请求地址可以是 http://sso.taotao.com/service/user/yuanleilei/1?r=0.950404558563605 需要返回json的请求 加上/service/..去掉.html。访问页面加上.html。请求风格也保持了统一。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[redis分片式集群，整合spring]]></title>
      <url>%2F2016%2F11%2F15%2Fredis%E5%88%86%E7%89%87%E5%BC%8F%E9%9B%86%E7%BE%A4%EF%BC%8C%E6%95%B4%E5%90%88spring%2F</url>
      <content type="text"><![CDATA[redis3.0之前使用的集群方式为 分片式集群。分片集群采用key的哈希值，来决定数据存储在那一台服务器上。分片集群依赖服务器的数量来进行key的哈希值计算，无法动态增加或减少服务节点。 分片式集群测试123456789101112131415161718192021222324252627282930313233343536373839404142434445import redis.clients.jedis.JedisPoolConfig;import redis.clients.jedis.JedisShardInfo;import redis.clients.jedis.ShardedJedis;import redis.clients.jedis.ShardedJedisPool;/** 集群式的连接池 */public class ShardedJedisPoolDemo &#123; public static void main(String[] args) &#123; // 构建连接池配置信息 JedisPoolConfig poolConfig = new JedisPoolConfig(); // 设置最大连接数 poolConfig.setMaxTotal(50); // 定义集群信息 List&lt;JedisShardInfo&gt; shards = new ArrayList&lt;JedisShardInfo&gt;(); // 一个服务，多个节点。。 shards.add(new JedisShardInfo("127.0.0.1", 6379)); shards.add(new JedisShardInfo("192.168.0.20", 6379)); // 定义集群连接池 ShardedJedisPool shardedJedisPool = new ShardedJedisPool(poolConfig, shards); ShardedJedis shardedJedis = null; try &#123; // 从连接池中获取到jedis分片对象 shardedJedis = shardedJedisPool.getResource(); /* for (int i=1;i&lt;=20;i++) &#123; shardedJedis.set("key" + i, "vlaue" + i); &#125;*/ // 从redis中获取数据 String value = shardedJedis.get("key6"); System.out.println(value); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != shardedJedis) &#123; // 关闭，检测连接是否有效，有效则放回到连接池中，无效则重置状态 shardedJedis.close(); &#125; &#125; // 关闭连接池 shardedJedisPool.close(); &#125;&#125; 存储的数据会以key计算哈希，存储到两台服务器上。获取的时候会以key计算哈希从两台服务器上取 整合spring与spring整合，就是构建分片式集群的上下分环境，创建出相应的数据对象，配置对象等，通过spring注入的方式来获取到即可。按照上面的代码逻辑，外围执行环境是ShardedJedisPool，ShardedJedisPool构建时需要有两个参数，配置信息 和 集群信息 JedisPoolConfig poolConfig = new JedisPoolConfig(); // 配置信息 List&lt;JedisShardInfo&gt; shards = new ArrayList&lt;JedisShardInfo&gt;(); // 集群信息 shards 中有多个JedisShardInfo ShardedJedisPool shardedJedisPool = new ShardedJedisPool(poolConfig, shards); applicationContext-redis.xml配置文件12345678910111213141516171819202122&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd"&gt; &lt;!-- redis连接池配置 --&gt; &lt;bean id="jedisPoolConfig" class="redis.clients.jedis.JedisPoolConfig"&gt; &lt;property name="maxTotal" value="$&#123;redis.maxTotal&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- redis 分片式集群 连接池 --&gt; &lt;bean class="redis.clients.jedis.ShardedJedisPool"&gt; &lt;constructor-arg index="0" ref="jedisPoolConfig" /&gt; &lt;constructor-arg index="1"&gt; &lt;list&gt; &lt;bean class="redis.clients.jedis.JedisShardInfo"&gt; &lt;constructor-arg index="0" value="$&#123;redis.node1.host&#125;" /&gt; &lt;constructor-arg index="1" value="$&#123;redis.node1.port&#125;" /&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/constructor-arg&gt; &lt;/bean&gt;&lt;/beans&gt; string类型的 set 和 get 操作12345678910111213141516171819202122232425262728293031323334353637383940414243@Servicepublic class RedisService &#123; @Autowired private ShardedJedisPool jedisPool; /** * set 操作 * @param key * @param value * @return */ public String set(String key, String value) &#123; ShardedJedis shardedJedis = null; try &#123; shardedJedis = jedisPool.getResource(); return shardedJedis.set(key, value); &#125; finally &#123; if (shardedJedis != null) &#123; // 关闭，检测连接是否有效，有效则放回到连接池中，无效则重置状态 shardedJedis.close(); &#125; &#125; &#125; /** * get 操作 * @param key * @return */ public String get(String key) &#123; ShardedJedis shardedJedis = null; try &#123; shardedJedis = jedisPool.getResource(); return shardedJedis.get(key); &#125; finally &#123; if (shardedJedis != null) &#123; // 关闭，检测连接是否有效，有效则放回到连接池中，无效则重置状态 shardedJedis.close(); &#125; &#125; &#125;&#125; 模板性代码封装上的的代码，重复太多，模板性的代码提出来。定义接口Function12345678public interface Function&lt;T, E&gt; &#123; /** * T 返回 类型，不确定，E 入参 不确定 * @param e * @return */ public T calback(E e);&#125; RedisService中。模板性代码提到execute方法中，入参为Function类型对象，可以确定入参类型为ShardedJedis。123456789101112private &lt;T&gt; T execute(Function&lt;T, ShardedJedis&gt; fun)&#123; ShardedJedis shardedJedis = null; try &#123; shardedJedis = jedisPool.getResource(); return fun.calback(shardedJedis); &#125; finally &#123; if (shardedJedis != null) &#123; // 关闭，检测连接是否有效，有效则放回到连接池中，无效则重置状态 shardedJedis.close(); &#125; &#125;&#125; 进一步确定返回类型set方法中调用execute，直接返回，那么返回类型确定 为String。别外，用人话讲，是因为作用域的问题，set方法的入参 需要用final关键字修饰。官方话讲，为了防止在调用外部变量的时候，该变量引用被修改，导致出现无法预料的问题。123456789/** set 操作 */public String set(final String key,final String value) &#123; return this.execute(new Function&lt;String, ShardedJedis&gt;() &#123; @Override public String calback(ShardedJedis e) &#123; return e.set(key, value); &#125; &#125;);&#125; 内部类中引用外部类的局部变量，需要用final修饰，这是合乎逻辑的：内部类执行完，局部变量销毁，外部类回调的时候该变量已经不存在了。“防止该引用被修改”。 代码预览123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899@Servicepublic class RedisService &#123; @Autowired private ShardedJedisPool jedisPool; /** * set 操作 * * @param key * @param value * @return */ public String set(final String key, final String value) &#123; return this.set(key, value, null); &#125; /** * set 操作 ，并设置 生存时间 * * @param key * @param value * @param seconds * @return */ public String set(final String key, final String value, final Integer seconds) &#123; return this.execute(new Function&lt;String, ShardedJedis&gt;() &#123; @Override public String calback(ShardedJedis e) &#123; String str = e.set(key, value); if (seconds != null) &#123; e.expire(key, seconds); &#125; return str; &#125; &#125;); &#125; /** * get 操作 * * @param key * @return */ public String get(final String key) &#123; return this.execute(new Function&lt;String, ShardedJedis&gt;() &#123; @Override public String calback(ShardedJedis e) &#123; return e.get(key); &#125; &#125;); &#125; /** * 删除 操作 * * @param key * @return */ public Long del(final String key) &#123; return this.execute(new Function&lt;Long, ShardedJedis&gt;() &#123; @Override public Long calback(ShardedJedis e) &#123; return e.del(key); &#125; &#125;); &#125; /** * 设置生存时间 * * @param key * @param seconds * 生存时间 * @return */ public Long expire(final String key, final int seconds) &#123; return this.execute(new Function&lt;Long, ShardedJedis&gt;() &#123; @Override public Long calback(ShardedJedis e) &#123; return e.expire(key, seconds); &#125; &#125;); &#125; private &lt;T&gt; T execute(Function&lt;T, ShardedJedis&gt; fun) &#123; ShardedJedis shardedJedis = null; try &#123; shardedJedis = jedisPool.getResource(); return fun.calback(shardedJedis); &#125; finally &#123; if (shardedJedis != null) &#123; // 关闭，检测连接是否有效，有效则放回到连接池中，无效则重置状态 shardedJedis.close(); &#125; &#125; &#125;&#125;]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[spring data jpa 复杂条件查询]]></title>
      <url>%2F2016%2F10%2F29%2Fspring-data-jpa-%E5%A4%8D%E6%9D%82%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2%2F</url>
      <content type="text"><![CDATA[使用 spring data jpa 封装的任意条件查询，可使用Pageable定义分页和排序。 一般方式定义接口，继承JpaRepository和JpaSpecificationExecutor。dao支持可以继承JpaRepository，条件查询可以继承JpaSpecificationExecutor。 12@(spring data jpa)Repository("resultInfoReposintory")public interface ResultInfoReposintory extends JpaRepository&lt;ResultInfo,Long&gt;,JpaSpecificationExecutor&lt;ResultInfo&gt; JpaSpecificationExecutor接口其中的两个方法 12List&lt;T&gt; findAll(Specification&lt;T&gt; spec); // 条件查询，不分页Page&lt;T&gt; findAll(Specification&lt;T&gt; spec, Pageable pageable); // 条件查询，分页和排序 代码实例 1234567891011121314// 构建Pageable对象，用于分页和排序int page = 0; // 当前页int pageSize = 20; // 每页显示多少条// 排序条件，以创建时间，更新时间 降序List&lt;Order&gt; orders = new ArrayList&lt;Sort.Order&gt;();orders.add(new Order(Direction.DESC, "createTime")); //createTime是ResultInfo实体中的属性名orders.add(new Order(Direction.DESC, "modifyTime"));Pageable pageable = new PageRequest(page,pageSize,new Sort(orders));// 构建查询条件对象 specificationSpecification&lt;ResultInfo&gt; specification = this.getSpecification(accNo, beginDate, endDate);// 执行分页查询Page&lt;ResultInfo&gt; page = resultInfoRepository.findAll(specification, pageable); 构建查询条件的方法。使用CriteriaQuery得到查询条件 123456789101112131415161718192021222324// 构建查询条件// root.get("accNo")中的accNo和 root.get("transDate")中的transDate，都是实体类中的属性名private Specification&lt;ResultInfo&gt; getSpecification(final String accNo, final String beginDate, final String endDate)&#123; Specification&lt;ResultInfo&gt; specification = new Specification&lt;ResultInfo&gt;() &#123; @Override public Predicate toPredicate(Root&lt;ResultInfo&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder cb) &#123; // 存储 多个在查询条件 List&lt;Predicate&gt; list = new ArrayList&lt;Predicate&gt;(); list.add(cb.equal(root.get("accNo").as(String.class), accNo)); Date begin = DateUtil.str2Date(beginDate, DateUtil.FORMAT_YYYY_MM_DD); Date end = DateUtil.str2Date(beginDate, DateUtil.FORMAT_YYYY_MM_DD); if(begin != null &amp;&amp; end != null)&#123; // 交易日期 list.add(cb.between(root.get("transDate").as(Date.class), begin, end)); &#125; Predicate[] p = new Predicate[list.size()]; return query.where(list.toArray(p)).getRestriction(); &#125; &#125;; return specification;&#125; 也可以使用CriteriaBuilder得到查询条件。下面代码的cb即是CriteriaBuilder的实例对象 12Predicate[] p = new Predicate[list.size()];return cb.and(list.toArray(p)); 最后会得到一个Page&lt;T&gt;对象实例，保存数据和分页信息。Page&lt;ResultInfo&gt; page = resultInfoRepository.findAll(specification, pageable);Page接口中的方法 12345678int getNumber(); // 当前页，第一页是0long getTotalElements(); // 总记录数int getSize(); // 每页显示多少条int getTotalPages(); // 总页数boolean isLast(); // 是否是最后一页boolean isFirst(); // 是否是第一页int getNumberOfElements(); // 当前页的记录条数List&lt;T&gt; getContent(); // 当前页的记录集合 自行封装构建复杂的查询条件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * @Description * @author leileiyuan * @date 2016年11月28日 上午10:11:26 */@Servicepublic class EnterpriseServiceImpl&#123; @Autowired private EnterpriseRepository enterpriseRepository; public Page&lt;Enterprise&gt; queryEnterpriseInfo(Enterprise enterprise) &#123; // 构建Pageable对象，用于分页和排序 int page = 0; // 当前页 int pageSize = 20; // 每页显示多少条 // 排序条件，以创建时间，更新时间 降序 List&lt;Order&gt; orders = new ArrayList&lt;Sort.Order&gt;(); orders.add(new Order(Direction.DESC, "createTime")); //createTime是Enterprise实体中的属性名 orders.add(new Order(Direction.DESC, "modifyTime")); Pageable pageable = new PageRequest(page,pageSize,new Sort(orders)); // 构建查询条件，我们已经把请求的查询条件放在入参 enterprise中， Criteria&lt;Enterprise&gt; spec = this.getSpecifications(enterprise); Page&lt;Enterprise&gt; data = enterpriseRepository.findAll(spec, pageable); return data; &#125; // 建构查询条件 private Criteria&lt;Enterprise&gt; getSpecifications(Enterprise enterprise) &#123; Criteria&lt;Enterprise&gt; criteria = new Criteria&lt;Enterprise&gt;(); // 默认条件 // 企业状态为“正常”和“已到期”并且 List&lt;String&gt; eStatus = new ArrayList&lt;String&gt;(); eStatus.add(EnterpriseStatusEnum.normal.getValue()); //eStatus.add(EnterpriseStatusEnum.overDue.getValue()); criteria.add(Restrictions.in("eStatus", eStatus)); // 企业状态 为 正常和已到期 // 审核状态为“风控审核通过”的 List&lt;String&gt; chkStatus = new ArrayList&lt;String&gt;(); chkStatus.add(OperationAuditStatusEnum.chkStatus4.getValue()); chkStatus.add(enterprise.getChkStatus()); // 审核状态 criteria.add(Restrictions.in("chkStatus", chkStatus)); criteria.add(Restrictions.like("eId", enterprise.getEId())); // 企业编号 criteria.add(Restrictions.like("eName", enterprise.getEName())); // 企业名称 // 入网开始时间 - 入网结束时间 Date joinDateBegin = enterprise.getJoinDateBegin(); Date joinDateEnd = enterprise.getJoinDateEnd(); if(joinDateBegin!=null &amp;&amp; joinDateEnd!=null)&#123; criteria.add(Restrictions.between("joinDate",joinDateBegin, joinDateEnd)); &#125; // 到期开始时间 - 到期结束时间 Date eDueDateBegin = enterprise.geteDueDateBegin(); Date eDueDateEnd = enterprise.geteDueDateEnd(); if(eDueDateBegin!=null &amp;&amp; eDueDateEnd!=null)&#123; criteria.add(Restrictions.between("eDueDate", eDueDateBegin,eDueDateEnd)); &#125; criteria.add(Restrictions.equal("eStatus", enterprise.getEStatus())); // 企业状态 return criteria; &#125; Criteria对象的封装。实现了Specification接口，重写public Predicate toPredicate(Root&lt;T&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder builder)方法。用来存储所有的查询条件。下面的代码中的toPredicate用来构建查询条件。是Criterion接口中的toPredicate 1234List&lt;Predicate&gt; predicates = new ArrayList&lt;Predicate&gt;(); for(Criterion c : criterions)&#123; predicates.add(c.toPredicate(root, query,builder)); &#125; Criteria对象完整代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.ArrayList;import java.util.List;import javax.persistence.criteria.CriteriaBuilder;import javax.persistence.criteria.CriteriaQuery;import javax.persistence.criteria.Predicate;import javax.persistence.criteria.Root;import org.springframework.data.jpa.domain.Specification;/** * Description: 查询条件的容器 * Predicate 为拼接好的条件或条件组合 * * @author leileiyuan * Create Date: 2016年11月28日 上午10:50:05 * @param &lt;T&gt; */public class Criteria&lt;T&gt; implements Specification&lt;T&gt; &#123; private List&lt;Criterion&gt; criterions = new ArrayList&lt;Criterion&gt;(); @Override public Predicate toPredicate(Root&lt;T&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder builder) &#123; if (!criterions.isEmpty()) &#123; List&lt;Predicate&gt; predicates = new ArrayList&lt;Predicate&gt;(); for(Criterion c : criterions)&#123; predicates.add(c.toPredicate(root, query,builder)); &#125; // 将所有条件用 and 联合起来 if (predicates.size() &gt; 0) &#123; return builder.and(predicates.toArray(new Predicate[predicates.size()])); &#125; &#125; // 返回一个没有联接条件的Predicate return builder.conjunction(); &#125; /** * Description: 增加简单的条件表达式 * * @param criterion * @author leileiyuan * Create Date: 2015年6月25日 下午2:43:13 */ public void add(Criterion criterion)&#123; if(criterion!=null)&#123; criterions.add(criterion); &#125; &#125; &#125; Criterion接口代码。定义条件表达式。toPredicate(...)方法，跟org.springframework.data.jpa.domain.Specification&lt;T&gt;接口的toPredicate方法一样。用来构建条件的。 12345678910111213141516171819202122232425262728293031323334353637383940414243import javax.persistence.criteria.CriteriaBuilder;import javax.persistence.criteria.CriteriaQuery;import javax.persistence.criteria.Predicate;import javax.persistence.criteria.Root;/** * Description: 条件表达式接口 * Criteria是一种类型安全和更面向对象的查询。 * * @author leileiyuan * Create Date: 2016年11月28日 上午10:51:07 */public interface Criterion &#123; public enum Operator &#123; EQ, // 等于 equal NE, // 不等于 notEqual GT, // 大于 greaterThan LT, // 小于 lessThan GTE, // 大于等于 greaterThanOrEqualTo LTE, // 小于等于 lessThanOrEqualTo BETWEEN, // 大于等于 并且 小于等于 between LIKE, // 模糊匹配 like OR, // 或者 or AND // 并且 and &#125; /** * Description: 代表一个条件或多个条件的组合 * * @param root * 代表Criteria查询的根对象，Criteria查询的查询根定义了实体类型，能为将来导航获得想要的结果 * @param query * CriteriaQuery 代表一个specific的顶层查询对象，包含查询的各个部分：如select 、from、where、group by、order by等 * @param builder * CriteriaBuilder 用来构造CriteriaQuery的构建对象 * @return Predicate 相当于条件或条件组合 * @author leileiyuan * Create Date: 2015年6月25日 上午11:02:31 */ public Predicate toPredicate(Root&lt;?&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder builder); &#125; Criterion接口的实现有两个，LogicalExpression和SimpleExpression。LogicalExpression用来构建逻辑表达式；SimpleExpression用来构建简单表达式 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.ArrayList;import java.util.List;import javax.persistence.criteria.CriteriaBuilder;import javax.persistence.criteria.CriteriaQuery;import javax.persistence.criteria.Predicate;import javax.persistence.criteria.Root;/** * Description: 逻辑表达式 ,用于复杂条件的联接 包含 AND OR * 形如select * from tableName where (expression1) and (expression2) * and 用来连接expression1 和expression2 这里的and就是逻辑表达式 * * @author leileiyuan * Create Date: 2016年11月28日 上午11:35:09 */public class LogicalExpression implements Criterion &#123; private Criterion[] criterions; // 逻辑表达式包含的表达式 private Operator operator; // 运算符 @Override public Predicate toPredicate(Root&lt;?&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder builder) &#123; // 存放 查询时要过滤的条件 List&lt;Predicate&gt; predicates = new ArrayList&lt;Predicate&gt;(); for (Criterion criterion : criterions) &#123; predicates.add(criterion.toPredicate(root, query, builder)); &#125; switch (operator) &#123; case AND: return builder.and(predicates.toArray(new Predicate[predicates.size()])); case OR: return builder.or(predicates.toArray(new Predicate[predicates.size()])); default: return null; &#125; &#125; public LogicalExpression() &#123; &#125; public LogicalExpression(Criterion[] criterions, Operator operator) &#123; super(); this.criterions = criterions; this.operator = operator; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import javax.persistence.criteria.CriteriaBuilder;import javax.persistence.criteria.CriteriaQuery;import javax.persistence.criteria.Expression;import javax.persistence.criteria.Path;import javax.persistence.criteria.Predicate;import javax.persistence.criteria.Root;/** * Description: 简单表达式。包括 EQ NE GT LT GTE LTE BETWEEN LIKE * * @author leileiyuan * Create Date: 2016年11月28日 上午11:16:58 */public class SimpleExpression implements Criterion &#123; private String fieldName; // 属性名 private Object value; // 属性所对应的值 private Object value2; // 属性所对应的值 使用在between时，第二个比较的数据值 private Operator operator; // 运算符 @SuppressWarnings(&#123; "rawtypes", "unchecked" &#125;) @Override public Predicate toPredicate(Root&lt;?&gt; root, CriteriaQuery&lt;?&gt; query, CriteriaBuilder builder) &#123; // TODO Auto-generated method stub Path expression = root.get(fieldName); switch (operator) &#123; case EQ: return builder.equal(expression, value); case NE: return builder.notEqual(expression, value); case GT: return builder.greaterThan(expression, (Comparable) value); case LT: return builder.lessThan(expression, (Comparable) value); case GTE: return builder.greaterThanOrEqualTo(expression, (Comparable) value); case LTE: return builder.lessThanOrEqualTo(expression, (Comparable) value); case BETWEEN: return builder.between(expression, (Comparable) value, (Comparable) value2); case LIKE: return builder.like((Expression&lt;String&gt;) expression, "%" + value +"%"); default: return null; &#125; &#125; public SimpleExpression() &#123; &#125; public SimpleExpression(String fieldName, Object value, Operator operator) &#123; super(); this.fieldName = fieldName; this.value = value; this.operator = operator; &#125; public SimpleExpression(String fieldName, Object value, Object value2, Operator operator) &#123; super(); this.fieldName = fieldName; this.value = value; this.value2 = value2; this.operator = operator; &#125; public String getFieldName() &#123; return fieldName; &#125; public void setFieldName(String fieldName) &#123; this.fieldName = fieldName; &#125; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125; public Object getValue2() &#123; return value2; &#125; public void setValue2(Object value2) &#123; this.value2 = value2; &#125; public Operator getOperator() &#123; return operator; &#125; public void setOperator(Operator operator) &#123; this.operator = operator; &#125; &#125; 逻辑表达式和简单表达式的条件构建 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183import java.util.Collection;import org.springframework.util.StringUtils;/** * Description: 条件构造器 * * @author leileiyuan * Create Date: 2016年11月28日 下午1:55:57 */public class Restrictions &#123; /** * Description: 等于 * * @param fieldName 属性名 * @param value 属性名对应的值 * @return * value为null返回null; * value如果是java.lang.String类型的实例 转换成String值为""，也返回null * @author leileiyuan * Create Date: 2016年11月28日 下午1:59:35 */ public static SimpleExpression equal(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.EQ); &#125; /** * Description: 不等于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:04:17 */ public static SimpleExpression notEqual(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.NE); &#125; /** * Description: 大于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:04:44 */ public static SimpleExpression greaterThan(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.GT); &#125; /** * Description: 小于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:05:35 */ public static SimpleExpression lessThan(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.LT); &#125; /** * Description: 大于等于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:07:22 */ public static SimpleExpression greaterThanOrEqualTo(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.GTE); &#125; /** * Description: 小于等于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:07:57 */ public static SimpleExpression lessThanOrEqualTo(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.LTE); &#125; /** * Description: 大于等于 并且 小于等于 * * @param fieldName * @param value * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:08:43 */ public static SimpleExpression between(String fieldName, Object value, Object value2) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, value2, Operator.BETWEEN); &#125; /** * Description: 模糊匹配 * * @param fieldName * @param value * @param value2 * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:10:04 */ public static SimpleExpression like(String fieldName, Object value) &#123; if (StringUtils.isEmpty(value)) &#123; return null; &#125; return new SimpleExpression(fieldName, value, Operator.LIKE); &#125; /** * Description: 并且 * * @param criterions * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:12:31 */ public static LogicalExpression and(Criterion...criterions)&#123; return new LogicalExpression(criterions, Operator.AND); &#125; /** * Description: 或者 * * @param criterions * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:13:06 */ public static LogicalExpression or(Criterion...criterions)&#123; return new LogicalExpression(criterions, Operator.OR); &#125; /** * Description: 包含于 * * @param fieldName * @param values * @return * @author leileiyuan * Create Date: 2016年11月28日 下午2:21:58 */ @SuppressWarnings("rawtypes") public static LogicalExpression in(String fieldName, Collection values)&#123; SimpleExpression[] ses = new SimpleExpression[values.size()]; int i = 0; for (Object value : values) &#123; ses[i] = new SimpleExpression(fieldName, value, Operator.EQ); i++; &#125; return new LogicalExpression(ses, Operator.OR); &#125;&#125; 到此封装就基本完成了。 spring data jpa还提供了更复杂的多表联接查询1234567891011121314151617public class Qfjbxxdz &#123; @Id @GeneratedValue(generator = "system-uuid") @GenericGenerator(name = "system-uuid", strategy = "uuid.hex") private String id; @OneToOne @JoinColumn(name = "qfjbxx") private Qfjbxx qfjbxx; //关联表 private String fzcc; private String fzccName; @ManyToOne @JoinColumn(name = "criminalInfo") private CriminalInfo criminalInfo;//关联表 @Column(length=800) private String bz; //get/set......&#125; 可以用类似的方法来调用。qfjbxx，criminalInfo是关联表的属性对象，id,xm分别是Qfjbxx和CriminalInfo实体类的属性 12Predicate p1 = cb.equal(root.join("qfjbxx").get("id").as(String.class), id);Predicate p2 = cb.like(root.join("criminalInfo").get("xm").as(String.class), "%"+xm+"%"); CriteriaQuery对象也支持分组和排序 12345// 设置groupBy的条件query.groupBy( root.get("qid").as(String.class), root.get("fid").as(String.class)); 12// 设置orderBy的条query.orderBy(cb.asc(root.get("xm").as(String.class)));]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用git访问远程gitub仓库]]></title>
      <url>%2F2016%2F10%2F22%2F%E4%BD%BF%E7%94%A8git%E8%AE%BF%E9%97%AE%E8%BF%9C%E7%A8%8Bgitub%E4%BB%93%E5%BA%93%2F</url>
      <content type="text"><![CDATA[在windows下安装msysgit，使用git命令操作仓库，并推送到远程github仓库。安装过以后，打开 Git Bash,会显示类型以下信息 leileiyuan@08-201508200156 MINGW64 ~ $ 输入git --version命令，显示版本号。 $ git --version git version 2.9.3.windows.2 本地建立工作环境，提交到远程仓库中。最简步骤： makdir blog -- 创建一个项目blog $ cd blog -- 打开这个项目 $ git init -- 初始化 $ touch README.md $ git add README.md -- 更新README文件 $ git commit -m &apos;first commit&apos; -- 提交更新，并注释信息“first commit” $ git remote add origin https://github.com/leileiyuan/hexoSource.git -- 连接远程github项目 $ git push -u origin master -- 将本地项目推动到远程仓库 目录文件比较多时，可以一次性add多个文件及目录 git add --all 或者 git add -A 从远程仓库中下载工程环境 git clone https://github.com/leileiyuan/hexoSource.git blog git add . git commit -m &quot;master commit&quot; git push origin clone下来的分支是master，在本地建立分支dev，切换到远程分支dev上(origin/dev) git checkout -b dev origin/dev 更新本地工程,合并工程 git pull &lt;远程主机名&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; git pull origin master:master 合并分支，将远程master合并到本地dev分支 git pull origin master:dev 将远程分支与当前分支合并 git pull origin dev 相当于git fetch 和 git merge先抓取远程数据，对比下有什么不同之处，再合并。这样操作相对安全一些。 合并分支把branchName合并到当前分支 git merge branchName 合并时，可能会有冲突。手动把有冲突的文件编辑以后，添加索引，再commit有冲突(conflicts)的文件会保存在索引中，除非你解决了问题了并且更新了索引，否则执行 git commit都会失败 创建分支 git branch branchName 切换分支 git checkout brancnName 创建并切换到分支 git checkout -b branchName 查看分支列表 git branch 不带参数：列出所有分支 gir branch -r 列出远程分支 gir branch -a 列出本地和远程分支 提交到远程仓库 git push &lt;远程主机名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; git push origin dev 如果当前分支与远程分支之间存在追踪关系，则本地分支和远程分支都可以省略。 $ git push origin]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[使用Hexo构建个人博客]]></title>
      <url>%2F2016%2F08%2F09%2F%E4%BD%BF%E7%94%A8hexo%E6%9E%84%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%BD%91%E7%AB%99%2F</url>
      <content type="text"><![CDATA[hexo是一个快速、简单的博客框架。可能通过Markdown语言编写文章。hexo来帮助你生成各种主题风格的静态网站，支持多终端访问 安装hexo之前需要先安装node和git。 安装hexo执行下面的命令安装hexo $ npm install -g hexo 查看是否安装成功 $ hexo -v 可能显示这些信息，说明hexo安装成功 hexo: 3.2.2 hexo-cli: 1.0.2 os: Windows_NT 6.1.7601 win32 x64 http_parser: 2.7.0 node: 6.2.0 v8: 5.0.71.47 uv: 1.9.1 zlib: 1.2.8 ares: 1.10.1-DEV icu: 57.1 modules: 48 openssl: 1.0.2h Hexo的使用初始化站点$ hexo init blog blog是你的站点目录。hexo会在blog下构建必要的目录结构，创建必要的配置文件等初始化好的目录结构： . ├── _config.yml ├── package.json ├── scaffolds/ ├── scripts/ ├── source/ | ├── _drafts | └── _posts └── themes/ 各目录结构说明 _config.yml：站点的全局配置文件。package.json：应用数据。从它可以看出Hexo的版本信息，依赖的组件。scaffolds/：模板文件目录。创建新文章的时候，通过模板生成scripts/：js脚本文件目录。source/：文章目录。整个站点的数据内容，图片等。_drafts：在source/目录下的子目录，草稿放在这里。_posts：在source/目录下的子目录，文章放在这里。themes/：主题目录。hexo默认主题是landscape，难看。通常会下载一些别的主题放在这个目录下来使用，主题一般也有自己的配置文件。 创建文章$ hexo new &quot;测试文章&quot; INFO Created: D:\blog\source\_posts\测试文章.md 在source/_posts目录下生成一篇文章 编辑文章用文本编辑器打开”测试文章.md”文件，文章内容如下： --- title: 测试文章 date: 2016-11-26 11:48:41 tags: --- 在文章结尾，输入一些内容： ### 这是一篇测试文章 hexo的基本使用。。。。。。 构建网站$ hexo generate 构建网站会在blog站点目录下，生成一个目录public，用来存放生成的所有站点文件 启动服务，预览博客$ hexo s INFO Start processing INFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 如果电脑上安装了Foxit Reader褔昕阅读器，端口可能被占用，需要手动指定端口 $ hexo s -p 5000 INFO Start processing INFO Hexo is running at http://localhost:5000/. Press Ctrl+C to stop. Ctrl+C停止服务 浏览器中访问 http://localhost:5000/ 即可看到生成的主页。 清理$ hexo clean INFO Deleted database. INFO Deleted public folder. 主要是把public目录删除掉了。 一般在使用hexo generate命令构建博客的时候，会先清理下。 Hexo 主题hexo有一套默认的主题，不过太难看了。一般会安装一套别的主题使用 安装next主题我用一套主题是Next,命令安装： $ git clone https://github.com/iissnan/hexo-theme-next themes/next 安装成功后，会在themes目录里多出一个目录next就是该主题的文件 启用主题打开blog/_config.yml站点全局配置文件，设置 theme: next 清理 构建博客 启动服务 浏览器中预览效果。 hexo clean hexo g hexo s -p 5000 部署如果自己的域名或空间，可以把博客直接部署上去 我是部署到github上，在站点全局配置文件中配置： deploy: type: git repository: https://github.com/leileiyuan/leileiyuan.github.io.git branch: master 执行部署命令 hexo deploy 可以将生成的部署命令组合使用 hexo d -g 或 hexo g -d，是指生成后立刻部署。 使用到的命令列表： $ hexo init -- 初始化网站 $ hexo new &quot;新文章名&quot; -- 创建新文章 $ hexo new page tags -- 创建标签，创始分类，创建其它结构的目录，都可以用 $ hexo clean -- 清理 $ hexo g -- generate 构建 $ hexo s -- server 启动本地服务 $ hexo d -- deploy 部署到远程服务器 $ hexo s -p 5000 -- 指定启动本地服务的端口 $ hexo g -d -- 生成后部署 参考 Hexo中文官网： https://hexo.io/zh-cn/ Next主题官网： http://theme-next.iissnan.com/]]></content>
    </entry>

    
  
  
</search>
